{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(5675)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam e-mail Classification with Machine Learning algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is it possible to reliably distinguish between spam and non-spam e-mails solely based on their content by the means of machine learning algorithms? Which of the most popular classification algorithm performs best at this task?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spam e-mails are a problem that almost all computer users face on a daily basis. The spam e-mails come from people they don't know or companies they are not familiar with and they clog their Inbox with irrelevant content. Latest statistics shows that spam messages accounted for 56.87% of e-mail traffic worldwide and the most familiar types of spam emails were healthcare and dating spam.[1]\n",
    "\n",
    "On one hand this problem is irritating, because important messages can be hidden under layers of spam and generally take extra time to sort, delete and read the important ones. This is especially bad at the workplace, where not filtering out the spam means lower overall performance and time wasted instead of focusing on the workload and therefore financial losses for the company. \n",
    "\n",
    "On the other hand the contents of spam e-mails can be harmful - they may contain malicious attachments or links that may infect the computer or threats and extortion messages that cause distress to the user. \n",
    "\n",
    "This is a well known issue that potentially has negative effects for both companies and individuals, which is why most e-mail services have developed intricate filtering mechanisms.  Completely automated solutions bounce or delete all suspected spam, while semi-automated solutions put suspected spam aside for a human to examine.[2] The goal of this project is to develop a model that learns based on already labeled as spam or non-spam e-mails and is then able to assign new incoming e-mails to one of the two groups. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models will be trained on data that describes the content of an e-mail in numerical word or character frequencies. The owners of the dataset have created a list of words and characters to use as a filter for their particular e-mails included in the set, so this is a very personalized set of words, and such should be individually created for other purposes with text processing tqchniques for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_%3B</th>\n",
       "      <th>char_freq_%28</th>\n",
       "      <th>char_freq_%5B</th>\n",
       "      <th>char_freq_%21</th>\n",
       "      <th>char_freq_%24</th>\n",
       "      <th>char_freq_%23</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0            0.00               0.64           0.64           0.0   \n",
       "1            0.21               0.28           0.50           0.0   \n",
       "2            0.06               0.00           0.71           0.0   \n",
       "3            0.00               0.00           0.00           0.0   \n",
       "4            0.00               0.00           0.00           0.0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0           0.32            0.00              0.00                0.00   \n",
       "1           0.14            0.28              0.21                0.07   \n",
       "2           1.23            0.19              0.19                0.12   \n",
       "3           0.63            0.00              0.31                0.63   \n",
       "4           0.63            0.00              0.31                0.63   \n",
       "\n",
       "   word_freq_order  word_freq_mail  ...  char_freq_%3B  char_freq_%28  \\\n",
       "0             0.00            0.00  ...           0.00          0.000   \n",
       "1             0.00            0.94  ...           0.00          0.132   \n",
       "2             0.64            0.25  ...           0.01          0.143   \n",
       "3             0.31            0.63  ...           0.00          0.137   \n",
       "4             0.31            0.63  ...           0.00          0.135   \n",
       "\n",
       "   char_freq_%5B  char_freq_%21  char_freq_%24  char_freq_%23  \\\n",
       "0            0.0          0.778          0.000          0.000   \n",
       "1            0.0          0.372          0.180          0.048   \n",
       "2            0.0          0.276          0.184          0.010   \n",
       "3            0.0          0.137          0.000          0.000   \n",
       "4            0.0          0.135          0.000          0.000   \n",
       "\n",
       "   capital_run_length_average  capital_run_length_longest  \\\n",
       "0                       3.756                          61   \n",
       "1                       5.114                         101   \n",
       "2                       9.821                         485   \n",
       "3                       3.537                          40   \n",
       "4                       3.537                          40   \n",
       "\n",
       "   capital_run_length_total  class  \n",
       "0                       278      1  \n",
       "1                      1028      1  \n",
       "2                      2259      1  \n",
       "3                       191      1  \n",
       "4                       191      1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_data = pd.read_csv('data/dataset_44_spambase.csv')\n",
    "spam_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data source: https://www.openml.org/d/44\n",
    "\n",
    "Original source: https://archive.ics.uci.edu/ml/datasets/spambase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a closer look at the data. There are 57 explanatory variables and 1 target.\n",
    "The target is in the last column 'class' and it takes two possible values:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1 when the e-mail is considered spam\n",
    "- 0 otherwise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features can be divided in 3 groups:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- word fequency columns with the header format word_freq_XXXX, where XXXX is a cecrtain word - 48 in total\n",
    "- character frequencies with the header format char_freq_YYYY, where YYYY is a certain character sqeuence - 6 in total\n",
    "- length of sequence of capitalized letters - average, longest and total - 3 in total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The frequencies are represented in percentages of all words and characters within one e-mail. All column names can be viewed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['word_freq_make', 'word_freq_address', 'word_freq_all', 'word_freq_3d',\n",
       "       'word_freq_our', 'word_freq_over', 'word_freq_remove',\n",
       "       'word_freq_internet', 'word_freq_order', 'word_freq_mail',\n",
       "       'word_freq_receive', 'word_freq_will', 'word_freq_people',\n",
       "       'word_freq_report', 'word_freq_addresses', 'word_freq_free',\n",
       "       'word_freq_business', 'word_freq_email', 'word_freq_you',\n",
       "       'word_freq_credit', 'word_freq_your', 'word_freq_font', 'word_freq_000',\n",
       "       'word_freq_money', 'word_freq_hp', 'word_freq_hpl', 'word_freq_george',\n",
       "       'word_freq_650', 'word_freq_lab', 'word_freq_labs', 'word_freq_telnet',\n",
       "       'word_freq_857', 'word_freq_data', 'word_freq_415', 'word_freq_85',\n",
       "       'word_freq_technology', 'word_freq_1999', 'word_freq_parts',\n",
       "       'word_freq_pm', 'word_freq_direct', 'word_freq_cs', 'word_freq_meeting',\n",
       "       'word_freq_original', 'word_freq_project', 'word_freq_re',\n",
       "       'word_freq_edu', 'word_freq_table', 'word_freq_conference',\n",
       "       'char_freq_%3B', 'char_freq_%28', 'char_freq_%5B', 'char_freq_%21',\n",
       "       'char_freq_%24', 'char_freq_%23', 'capital_run_length_average',\n",
       "       'capital_run_length_longest', 'capital_run_length_total', 'class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data should be inspected for missing values and wrong data types before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4601 entries, 0 to 4600\n",
      "Data columns (total 58 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   word_freq_make              4601 non-null   float64\n",
      " 1   word_freq_address           4601 non-null   float64\n",
      " 2   word_freq_all               4601 non-null   float64\n",
      " 3   word_freq_3d                4601 non-null   float64\n",
      " 4   word_freq_our               4601 non-null   float64\n",
      " 5   word_freq_over              4601 non-null   float64\n",
      " 6   word_freq_remove            4601 non-null   float64\n",
      " 7   word_freq_internet          4601 non-null   float64\n",
      " 8   word_freq_order             4601 non-null   float64\n",
      " 9   word_freq_mail              4601 non-null   float64\n",
      " 10  word_freq_receive           4601 non-null   float64\n",
      " 11  word_freq_will              4601 non-null   float64\n",
      " 12  word_freq_people            4601 non-null   float64\n",
      " 13  word_freq_report            4601 non-null   float64\n",
      " 14  word_freq_addresses         4601 non-null   float64\n",
      " 15  word_freq_free              4601 non-null   float64\n",
      " 16  word_freq_business          4601 non-null   float64\n",
      " 17  word_freq_email             4601 non-null   float64\n",
      " 18  word_freq_you               4601 non-null   float64\n",
      " 19  word_freq_credit            4601 non-null   float64\n",
      " 20  word_freq_your              4601 non-null   float64\n",
      " 21  word_freq_font              4601 non-null   float64\n",
      " 22  word_freq_000               4601 non-null   float64\n",
      " 23  word_freq_money             4601 non-null   float64\n",
      " 24  word_freq_hp                4601 non-null   float64\n",
      " 25  word_freq_hpl               4601 non-null   float64\n",
      " 26  word_freq_george            4601 non-null   float64\n",
      " 27  word_freq_650               4601 non-null   float64\n",
      " 28  word_freq_lab               4601 non-null   float64\n",
      " 29  word_freq_labs              4601 non-null   float64\n",
      " 30  word_freq_telnet            4601 non-null   float64\n",
      " 31  word_freq_857               4601 non-null   float64\n",
      " 32  word_freq_data              4601 non-null   float64\n",
      " 33  word_freq_415               4601 non-null   float64\n",
      " 34  word_freq_85                4601 non-null   float64\n",
      " 35  word_freq_technology        4601 non-null   float64\n",
      " 36  word_freq_1999              4601 non-null   float64\n",
      " 37  word_freq_parts             4601 non-null   float64\n",
      " 38  word_freq_pm                4601 non-null   float64\n",
      " 39  word_freq_direct            4601 non-null   float64\n",
      " 40  word_freq_cs                4601 non-null   float64\n",
      " 41  word_freq_meeting           4601 non-null   float64\n",
      " 42  word_freq_original          4601 non-null   float64\n",
      " 43  word_freq_project           4601 non-null   float64\n",
      " 44  word_freq_re                4601 non-null   float64\n",
      " 45  word_freq_edu               4601 non-null   float64\n",
      " 46  word_freq_table             4601 non-null   float64\n",
      " 47  word_freq_conference        4601 non-null   float64\n",
      " 48  char_freq_%3B               4601 non-null   float64\n",
      " 49  char_freq_%28               4601 non-null   float64\n",
      " 50  char_freq_%5B               4601 non-null   float64\n",
      " 51  char_freq_%21               4601 non-null   float64\n",
      " 52  char_freq_%24               4601 non-null   float64\n",
      " 53  char_freq_%23               4601 non-null   float64\n",
      " 54  capital_run_length_average  4601 non-null   float64\n",
      " 55  capital_run_length_longest  4601 non-null   int64  \n",
      " 56  capital_run_length_total    4601 non-null   int64  \n",
      " 57  class                       4601 non-null   int64  \n",
      "dtypes: float64(55), int64(3)\n",
      "memory usage: 2.0 MB\n"
     ]
    }
   ],
   "source": [
    "spam_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "It seems like the dataset has no missing data and the data types are correctly recognized. All are numerical as expected.\n",
    "\n",
    "It is also important to check whether the two target classes are equally represented within the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (4, 4))\n",
    "plt.pie(spam_data['class'].value_counts(),labels = ['Not Spam', 'Spam'], autopct = '%1.1f%%', startangle=90)\n",
    "plt.axis('equal')\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Around 60% of the recorded data represents non-spam e-mails and 40% is spam. Though the dataset is not perfectly balanced, this is an acceptable ratio between the count of observations within each class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section the given data will be first divided in two - features and target (labels). This is done because the uderlying task of this project is one of supervised learning, where the real output is known and compared to the predictions of the models.\n",
    "\n",
    "Then the will be split into training, validation and testing sets. Validation and testing will include roughly 700 records or 15% of the data each, while the most part of the set will be left for training (70% or around 3000 records). The stratisfy argument is passed to the train_test_split function, so that spam e-mails are evenly distributed in all sets and the ratio spam/non-spam is maintained. The chosen models will be first trained on the train set as usual. The validation set will be used for scoring to fine-tune the hyperparameters of the models and hopefully increase their accuracy and other scores. This method of validation is chosen over the widely used cross-validation folds in order to reduce computation time and because it will be used on quite a few differently tuned models.\n",
    "\n",
    "Lastly the data in each set will be scaled with a StandardScaler() separately. This step ensures the better performance of the classification algorithms, decision trees and support vector machines in particular. Every set is scaled on it's own so that information from the training set doest not 'spill' into the testing and validation sets. We treat them as records that are obtained after the development of the models, therefore as brand new data points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_features = spam_data.drop('class', axis = 1)\n",
    "spam_target = spam_data['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_features_train, spam_features_testandnval, spam_target_train, spam_target_testandval = train_test_split(spam_features, spam_target, train_size = 0.7, stratify = spam_target, random_state = 5675)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_features_val, spam_features_test, spam_target_val, spam_target_test = train_test_split(spam_features_testandnval, spam_target_testandval, test_size = 0.5, stratify = spam_target_testandval, random_state = 5675)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3220, 57)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_features_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(690, 57)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_features_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(691, 57)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_features_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "spam_features_train_scaled = scaler.fit_transform(spam_features_train)\n",
    "spam_features_val_scaled = scaler.transform(spam_features_val)\n",
    "spam_features_test_scaled = scaler.transform(spam_features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Improving Models\n",
    "\n",
    "In this section the most well-known classification models will be compared and namely: \n",
    "\n",
    "- Logistic Regression\n",
    "- Support Vector Machine\n",
    "- Decision Tree\n",
    "\n",
    "The strategy for the proccess of tuning the parameters will follow this route - first check the performance of the baseline models without any tuning to have a starting point and a validation set score for comparison. Then for each model the few most impactful parameters will be tuned to try and improve the score. Finally, the model with the highest performance on the validation set will be chosen and scored on the training set.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. Base models with default hyperparameters\n",
    "\n",
    "Here are the default models witht their hyperparameters provided by scikit-learn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=5675, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_logit = LogisticRegression(random_state = 5675)\n",
    "default_logit.fit(spam_features_train_scaled, spam_target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=5675, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_SVM = SVC(random_state=5675)\n",
    "default_SVM.fit(spam_features_train_scaled, spam_target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=5675, splitter='best')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_tree = DecisionTreeClassifier(random_state=5675)\n",
    "default_tree.fit(spam_features_train_scaled, spam_target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Hyperparameter tuning\n",
    "\n",
    "For this part of the project it is not realistic to try all different combinations of parameters to achieve some sort of improvement. That's why it is preferable to focus on just a few parameters for each algorithm, which have the most impact on the score and then try different combinations of the parameters with GridSearchCV. \n",
    "\n",
    "First let's choose two to three most important parameters for each model and then decide also three to four reasonable values within a given range for those hyperparameters. This limitation to fewer hyperparameters and smaller value ranges is for the purpose of lowering computational complexity, while still achieving good results. [3] \n",
    "\n",
    "According to an article on tuning hyperparameters [4] ponints out that for Logistic Regression parameters that could lead to an improvement are the penalty strength C, the solver and regularization penalty. The same source says that for SVM the important hyper parameters are also C (on a logaritmic scale) and the kernels that go hand in hand with the kernel coefficient gamma. For Decision trees it is advisable to tune among others the criterion on which that the split is based, max_depth that controls the levels of the tree and min_samples_leaf that is the minimum number of samples that are each final node (leaf) contains.[5]\n",
    "\n",
    "Here is a summary of the chosen hyperparameters and their values that will be used for tuning:\n",
    "\n",
    "##### Logistic Regression\n",
    "- C: 1, 10, 100, 1000; \n",
    "- penalty: 'l1', 'l2';\n",
    "- solver: 'liblinear', 'saga', 'lbfgs'; \n",
    "\n",
    "The idea here is to increase the penalty strength and therefore reduce regularization (C = 1/lambda) and try 'l1' and 'l2' penalties that set coefficients to 0 or just reduce them respectively and try out different solvers, chosen to support either one or both types of penatlies.\n",
    "\n",
    "#####  Support Vector Machine\n",
    "\n",
    "- C: 1, 10, 100; \n",
    "- gamma: 0.01, 0.001, 0.0001; \n",
    "- kernel: 'rbf', 'linear';\n",
    "\n",
    "In this case the penalty strenth is also increased on exponential scale, as well as two differen kernels - the linear and the Gaussian that maps the data in multiple dimensions to see which will be better at the task of separating the emails. The kernel coefficient gamma is passed only for the rbf kernel and is and again small exponentially decreasing values are chosen. The role of gamma is to determin how far two points can be and still be considered similar, as smaller gammas increase this distance. \n",
    "\n",
    "##### Decision Tree\n",
    "\n",
    "- criterion: 'gini'; 'entropy'; \n",
    "- max_depth: 10, 5, 3, None; \n",
    "- min_samples_leaf: 1, 5, 10, 50\n",
    "\n",
    "For the decision tree the tuned hyperparameters will be the impurity measure or criterion for splitting - gini or entropy, to see which one performs better even though they are very similar. Different values form max_depth in the range oe 3 to 10 will be tried out to see if pruning will give better results. The same goes for the other hyperparameter, namely min_samples_leaf that could stop the splitting earlier with growing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [{'C': [1, 10, 100, 1000], 'solver': ['saga', 'liblinear'], 'penalty':['l2','l1']},\n",
    "           {'C': [1, 10, 100, 1000], 'solver': ['lbfgs'], 'penalty':['l2']}]\n",
    "\n",
    "grid_search_logit = GridSearchCV(LogisticRegression(random_state = 5675), params, cv = 10, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Desy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score=nan,\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='auto',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=5675, solver='lbfgs',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid=[{'C': [1, 10, 100, 1000], 'penalty': ['l2', 'l1'],\n",
       "                          'solver': ['saga', 'liblinear']},\n",
       "                         {'C': [1, 10, 100, 1000], 'penalty': ['l2'],\n",
       "                          'solver': ['lbfgs']}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_logit.fit(spam_features_train_scaled, spam_target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tuned_logit = grid_search_logit.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_logit.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9288819875776397"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_logit.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [{'C': [1, 10, 100], 'gamma': [0.01, 0.001, 0.0001], 'kernel': ['rbf']},\n",
    "         {'C': [1, 10, 100], 'kernel': ['linear']}]\n",
    "grid_search_SVM = GridSearchCV(SVC(random_state=5675), params, cv = 10, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score=nan,\n",
       "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                           class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=5675, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid=[{'C': [1, 10, 100], 'gamma': [0.01, 0.001, 0.0001],\n",
       "                          'kernel': ['rbf']},\n",
       "                         {'C': [1, 10, 100], 'kernel': ['linear']}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_SVM.fit(spam_features_train_scaled, spam_target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=5675, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_SVM.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_SVM.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9388198757763975"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_SVM.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_SVM = grid_search_SVM.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"max_depth\": [10, 5, 3, None],\n",
    "          \"min_samples_leaf\": [1, 5, 10, 50],\n",
    "          \"criterion\": [\"gini\", \"entropy\"]}\n",
    "grid_search_tree = GridSearchCV(DecisionTreeClassifier(random_state=5675), params, cv = 10, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score=nan,\n",
       "             estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features=None,\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              presort='deprecated',\n",
       "                                              random_state=5675,\n",
       "                                              splitter='best'),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [10, 5, 3, None],\n",
       "                         'min_samples_leaf': [1, 5, 10, 50]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_tree.fit(spam_features_train_scaled, spam_target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tuned_tree = grid_search_tree.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 5}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_tree.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9201863354037266"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_tree.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final evaluation and best model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression before tuning is 92.4638 % and after tuning is 92.8986 %. Increase of 0.4347826086956559\n",
      "Accuracy of Support Vector Classifier before tuning 92.8986 % and after tuning is 93.4783 %. Increase of 0.5797101449275317\n",
      "Accuracy of Decision tree Classifier before tuning 92.1739 % and after tuning is 92.8986 %. Increase of 0.28985507246376585\n"
     ]
    }
   ],
   "source": [
    "default_logit_score = default_logit.score(spam_features_val_scaled, spam_target_val)*100\n",
    "default_SVM_score = default_SVM.score(spam_features_val_scaled, spam_target_val)*100\n",
    "default_tree_score = default_tree.score(spam_features_val_scaled, spam_target_val)*100\n",
    "\n",
    "tuned_logit_score = tuned_logit.score(spam_features_val_scaled, spam_target_val)*100\n",
    "tuned_SVM_score = tuned_SVM.score(spam_features_val_scaled, spam_target_val)*100\n",
    "tuned_tree_score = tuned_tree.score(spam_features_val_scaled, spam_target_val)*100\n",
    "\n",
    "print(f'Accuracy of Logistic Regression before tuning is {default_logit_score:0.4f} % and after tuning is {tuned_logit_score:.4f} %. Increase of {tuned_logit_score - default_logit_score}')\n",
    "print(f'Accuracy of Support Vector Classifier before tuning {default_SVM_score:0.4f} % and after tuning is {tuned_SVM_score:.4f} %. Increase of {tuned_SVM_score - default_SVM_score}')\n",
    "print(f'Accuracy of Decision tree Classifier before tuning {default_tree_score:0.4f} % and after tuning is {tuned_logit_score:.4f} %. Increase of {tuned_tree_score - default_tree_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we have very good models to begin with, the improvment by tuning as seen above is not dramatic. However, the best performing model after tuning is the Support Vector Classifier, let's see how it performs on unseen data, measured by other common classification scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94       419\n",
      "           1       0.92      0.89      0.90       272\n",
      "\n",
      "    accuracy                           0.92       691\n",
      "   macro avg       0.92      0.92      0.92       691\n",
      "weighted avg       0.92      0.92      0.92       691\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(spam_target_test, tuned_SVM.predict(spam_features_test_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[397  22]\n",
      " [ 31 241]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(spam_target_test, tuned_SVM.predict(spam_features_test_scaled)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The support vector classifier shows satisfactory scores and was abe to correctly classify 397 out of the 419 non-spam e-mails (True Negatives) and 241 out of 272 spam e-mails (True Positives). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, it is obvious that the developed filter for spam e-mails in this dataset is a good indicator to destinguis between spam and non-spam and all tested machine learning algorithms performed quite good. Trough series of tuning experiments we arrived at a somewhat improved model and selected the tuned Support Vector Classifier out of all models and it gives high results for all classification scores such as accuracy, precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] Emmanuel Gbenga Dada, Joseph Stephen Bassi, Haruna Chiroma, Shafi'i Muhammad Abdulhamid, Adebayo Olusola Adetunmbi, Opeyemi Emmanuel Ajibuwa, Machine learning for email spam filtering: review, approaches and open research problems, Heliyon, Volume 5, Issue 6, 2019, e01802, ISSN 2405-8440,https://doi.org/10.1016/j.heliyon.2019.e01802 (http://www.sciencedirect.com/science/article/pii/S2405844018353404)\n",
    "\n",
    "[2] Lorrie Faith Cranor and Brian A. LaMacchia. Spam! Communications of the ACM. Vol. 41, No. 8 (Aug. 1998), Pages 74-83. Definitive version: http://www.acm.org/pubs/citations/journals/cacm/1998-41-8/p74-cranor/\n",
    "\n",
    "[3] Amazon SageMaker Developer Guide, Best Practices for Hyperparameter Tuning, https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-considerations.html\n",
    "\n",
    "[4] Jason Brownlee, Tune Hyperparameters for Classification Machine Learning Algorithms, https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n",
    "\n",
    "[5] Mukesh Mithrakumar, How to tune a Decision Tree?, https://towardsdatascience.com/how-to-tune-a-decision-tree-f03721801680 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
